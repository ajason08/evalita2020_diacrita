{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt0_raw_cbow = Word2Vec.load(\"raw/t0_lower_cbow_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_raw_cbow = Word2Vec.load(\"raw/t1_lower_cbow_d256w5m3e10_n22_s5.w2v\")\n",
    "\n",
    "mt0_raw_skip = Word2Vec.load(\"raw/t0_lower_skip_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_raw_skip = Word2Vec.load(\"raw/t1_lower_skip_d256w5m3e10_n22_s5.w2v\")\n",
    "\n",
    "mt0_lemmas_cbow = Word2Vec.load(\"lemmas/t0_lower_cbow_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_lemmas_cbow = Word2Vec.load(\"lemmas/t1_lower_cbow_d256w5m3e10_n22_s5.w2v\")\n",
    "\n",
    "mt0_lemmas_skip = Word2Vec.load(\"lemmas/t0_lower_skip_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_lemmas_skip = Word2Vec.load(\"lemmas/t1_lower_skip_d256w5m3e10_n22_s5.w2v\")\n",
    "\n",
    "mt0_rawpos_cbow = Word2Vec.load(\"raw_pos/t0_lower_cbow_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_rawpos_cbow = Word2Vec.load(\"raw_pos/t1_lower_cbow_d256w5m3e10_n22_s5.w2v\")\n",
    "\n",
    "mt0_rawpos_skip = Word2Vec.load(\"raw_pos/t0_lower_skip_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_rawpos_skip = Word2Vec.load(\"raw_pos/t1_lower_skip_d256w5m3e10_n22_s5.w2v\")\n",
    "\n",
    "mt0_lemmaspos_cbow = Word2Vec.load(\"lemmas_pos/t0_lower_cbow_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_lemmaspos_cbow = Word2Vec.load(\"lemmas_pos/t1_lower_cbow_d256w5m3e10_n22_s5.w2v\")\n",
    "\n",
    "mt0_lemaspos_skip = Word2Vec.load(\"lemmas_pos/t0_lower_skip_d256w5m3e40_n22_s5.w2v\")\n",
    "mt1_lemaspos_skip = Word2Vec.load(\"lemmas_pos/t1_lower_skip_d256w5m3e10_n22_s5.w2v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goldstandard y diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOLDEN_TARGETS = {\"egemonizzare\":0,\"lucciola\":1,\"campanello\":0,\"trasferibile\":0,\"brama\":0,\"polisportiva\":0,\"palmare\":1,\n",
    "                  \"processare\":0,\"pilotato\":1,\"cappuccio\":0,\"pacchetto\":0,\"ape\":1,\"unico\":0,\"discriminatorio\":0,\"rampante\":1,\"campionato\":0,\"tac\":1,\"piovra\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "infile = open(\"target_t0_dict.pkl\",'rb')\n",
    "target_t0_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "infile = open(\"target_t1_dict.pkl\",'rb')\n",
    "target_t1_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordlist(dic, typ):\n",
    "    word_list = []\n",
    "    for word in dic.keys():\n",
    "        if typ == \"raw\":\n",
    "            word_list.append({word:dic[word][\"golden\"]})\n",
    "        if typ == \"raw_pos\":\n",
    "            for pos in dic[word][\"pos\"].keys():\n",
    "                word_list.append({f\"{word}_{pos}\":dic[word][\"golden\"]})\n",
    "        if typ == \"lemma\":\n",
    "            for pos in dic[word][\"pos\"].keys():\n",
    "                for lemma in dic[word][\"pos\"][pos][\"lemmas\"].keys():\n",
    "                    if not {f\"{lemma}\":dic[word][\"golden\"]} in word_list:\n",
    "                        word_list.append({f\"{lemma}\":dic[word][\"golden\"]})\n",
    "        if typ == \"lemma_pos\":\n",
    "            for pos in dic[word][\"pos\"].keys():\n",
    "                for lemma in dic[word][\"pos\"][pos][\"lemmas\"].keys():\n",
    "                    if not {f\"{lemma}_{pos}\":dic[word][\"golden\"]} in word_list:\n",
    "                        word_list.append({f\"{lemma}_{pos}\":dic[word][\"golden\"]})\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volcar todas las similitudes de una palabra en dos modelos a un dataframe y vizualizarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn2df(model0, model1, target_word):\n",
    "    if target_word in list(model0.wv.vocab) and target_word in list(model1.wv.vocab):\n",
    "        df0 = pd.DataFrame(model0.wv.most_similar(target_word, topn = model0.corpus_total_words), columns=[\"nn\",\"t0\"])\n",
    "        #df0[\"t0_rank\"] = df0[\"t0\"].rank(ascending=False)\n",
    "        df0.set_index(\"nn\", inplace=True)\n",
    "    \n",
    "        df1 = pd.DataFrame(model1.wv.similar_by_vector(target_word, topn = model1.corpus_total_words), columns=[\"nn\", \"t1\" ])\n",
    "        #df1[\"t1_rank\"] = abs(df1[\"t1\"]).rank(ascending=False)\n",
    "        df1.set_index(\"nn\", inplace=True)\n",
    "    \n",
    "        df = pd.concat([df0,df1], axis=1)\n",
    "        df.dropna(thresh=2, inplace=True)\n",
    "        \n",
    "        df[\"dif_abs\"] = abs(df[\"t0\"]-df[\"t1\"])\n",
    "        \n",
    "        df[\"rank_0\"] = df[\"t0\"].rank()\n",
    "        df[\"rank_1\"] = df[\"t1\"].rank()\n",
    "        \n",
    "        #df[\"dif_rank\"] = abs(df[\"rank_0\"]-df[\"rank_1\"])\n",
    "        #version_cuadratica\n",
    "        df[\"dif_rank\"] = abs(df[\"rank_0\"]-df[\"rank_1\"])**2\n",
    "        \n",
    "        df.index.name = target_word\n",
    "        return df\n",
    "    else:\n",
    "        print(f'{target_word}  No esta en los dos modelos, no se puede comparar!!!')\n",
    "        return pd.DataFrame(columns=[\"nn\",\"t0\",\"t1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.close(\"all\")\\n\\nwords = [\"pomodoro\", \"palmare\"]\\nhistogramas(words, \"t0\", 50)\\nhistogramas(words, \"t1\", 50)\\nhistogramas(words, \"dif_abs\", 50)\\nhistogramas(words, \"dif_rank\", 50)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def histogramas_palabras(words, column, bins):\n",
    "    words_dataframe = pd.DataFrame()\n",
    "    words_dataframe.index.name = \"palabra_vecina\"\n",
    "    if type(words) == list:\n",
    "        for word in words:\n",
    "            w = nn2df(mt0_raw_cbow, mt1_raw_cbow, word)\n",
    "            words_dataframe[word] = w[column]\n",
    "        words_dataframe.hist(bins = bins,sharex=True, sharey=True)\n",
    "     \n",
    "\"\"\"plt.close(\"all\")\n",
    "\n",
    "words = [\"pomodoro\", \"palmare\"]\n",
    "histogramas(words, \"t0\", 50)\n",
    "histogramas(words, \"t1\", 50)\n",
    "histogramas(words, \"dif_abs\", 50)\n",
    "histogramas(words, \"dif_rank\", 50)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular diferencias de distintos tipos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w1 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\").sort_values(by=\"t1\")\\nw2 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"lucciola\").sort_values(by=\"t1\")\\nlogspace = []\\n[logspace.append(int(round(x))) for x in np.logspace(0.1, math.log(w.shape[0],10), base=10, num=10) if int(round(x)) not in logspace]\\np1=promedio_k_diferencias(w1, logspace, sort_by=\"t0\")\\np2=promedio_k_diferencias(w2, logspace, sort_by=\"t0\")\\np = pd.DataFrame()\\np[\"pomodoro\"] = p1[\"dif_abs\"]\\np[\"lucciola\"] = p2[\"dif_abs\"]\\n\\np2'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def promedio_k_diferencias(nn2df,k_lista, sort_by=\"t0\"):\n",
    "    diferencias = pd.DataFrame()\n",
    "    for k in k_lista:\n",
    "        #Nuestro (Sin union)\n",
    "        #serie_promedios = nn2df.sort_values(by=sort_by,ascending=False)[[\"dif_abs\",\"dif_rank\"]].head(k).mean()\n",
    "        #serie_promedios.name = k\n",
    "        \n",
    "        #Hamilton (unido)\n",
    "        # Hamilton\n",
    "        dfk1 = nn2df.sort_values(by=\"t0\", ascending=False)[[\"dif_abs\",\"dif_rank\"]].head(k)\n",
    "        dfk2 = nn2df.sort_values(by=\"t1\", ascending=False)[[\"dif_abs\",\"dif_rank\"]].head(k)\n",
    "        dfk = pd.concat([dfk1, dfk2], ignore_index = True)\n",
    "        dfk = dfk.drop_duplicates()\n",
    "        serie_promedios = dfk[[\"dif_abs\",\"dif_rank\"]].head(k).mean()\n",
    "        serie_promedios.name = k        \n",
    "\n",
    "        \n",
    "        diferencias = diferencias.append(serie_promedios)\n",
    "    diferencias.index.name = nn2df.index.name\n",
    "    return diferencias      \n",
    "                         \n",
    "\"\"\"w1 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\").sort_values(by=\"t1\")\n",
    "w2 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"lucciola\").sort_values(by=\"t1\")\n",
    "logspace = []\n",
    "[logspace.append(int(round(x))) for x in np.logspace(0.1, math.log(w.shape[0],10), base=10, num=10) if int(round(x)) not in logspace]\n",
    "p1=promedio_k_diferencias(w1, logspace, sort_by=\"t0\")\n",
    "p2=promedio_k_diferencias(w2, logspace, sort_by=\"t0\")\n",
    "p = pd.DataFrame()\n",
    "p[\"pomodoro\"] = p1[\"dif_abs\"]\n",
    "p[\"lucciola\"] = p2[\"dif_abs\"]\n",
    "\n",
    "p2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w1 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\").sort_values(by=\"t1\")\\nw2 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"lucciola\").sort_values(by=\"t1\")\\nlogspace = []\\n[logspace.append(int(round(x))) for x in np.logspace(0.1, math.log(w.shape[0],10), base=10, num=10) if int(round(x)) not in logspace]\\np1=scoseno_k_diferencias(w1, logspace, sort_by=\"t0\")\\np2=scoseno_k_diferencias(w2, logspace, sort_by=\"t0\")\\np = pd.DataFrame()\\np[\"pomodoro\"] = p1[\"scos_r0_r1\"]\\np[\"lucciola\"] = p2[\"scos_r0_r1\"]\\np'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scoseno_k_diferencias(nn2df,k_lista, sort_by=\"t0\"):\n",
    "    scosenos = pd.DataFrame()\n",
    "    for k in k_lista:\n",
    "        dfk = nn2df.sort_values(by=sort_by, ascending=False)[[\"t0\",\"t1\",\"rank_0\",\"rank_1\"]].head(k)\n",
    "        scos_t0_t1 = cosine_similarity(dfk['t0'].values.reshape(1, -1),dfk['t1'].values.reshape(1, -1))[0][0]\n",
    "        scos_r0_r1 = cosine_similarity(dfk['rank_0'].values.reshape(1, -1),dfk['rank_1'].values.reshape(1, -1))[0][0]\n",
    "        scos = pd.Series({\"scos_t0_t1\":scos_t0_t1, \"scos_r0_r1\":scos_r0_r1})\n",
    "        \n",
    "        #diferencia_coseno\n",
    "        #scos_t0_t1 = 1-cosine_similarity(dfk['t0'].values.reshape(1, -1),dfk['t1'].values.reshape(1, -1))[0][0]\n",
    "        #scos_r0_r1 = 1-cosine_similarity(dfk['rank_0'].values.reshape(1, -1),dfk['rank_1'].values.reshape(1, -1))[0][0]\n",
    "        #scos = pd.Series({\"scos_t0_t1\":scos_t0_t1, \"scos_r0_r1\":scos_r0_r1})\n",
    "        \n",
    "        # Hamilton\n",
    "        \"\"\"dfk1 = nn2df.sort_values(by=\"t0\", ascending=False)[[\"t0\",\"t1\",\"rank_0\",\"rank_1\"]].head(k)\n",
    "        dfk2 = nn2df.sort_values(by=\"t1\", ascending=False)[[\"t0\",\"t1\",\"rank_0\",\"rank_1\"]].head(k)\n",
    "        dfk = pd.concat([dfk1, dfk2], ignore_index = True)\n",
    "        dfk = dfk.drop_duplicates()\n",
    "        scos_t0_t1 = 1-cosine_similarity(dfk['t0'].values.reshape(1, -1),dfk['t1'].values.reshape(1, -1))[0][0]\n",
    "        scos_r0_r1 = 1-cosine_similarity(dfk['rank_0'].values.reshape(1, -1),dfk['rank_1'].values.reshape(1, -1))[0][0]\n",
    "        scos = pd.Series({\"scos_t0_t1\":scos_t0_t1, \"scos_r0_r1\":scos_r0_r1})\"\"\"\n",
    "        \n",
    "        scos.name = k\n",
    "        scosenos = scosenos.append(scos)\n",
    "    scosenos.index.name = nn2df.index.name\n",
    "    return scosenos\n",
    "        \n",
    "                          \n",
    "\"\"\"w1 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\").sort_values(by=\"t1\")\n",
    "w2 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"lucciola\").sort_values(by=\"t1\")\n",
    "logspace = []\n",
    "[logspace.append(int(round(x))) for x in np.logspace(0.1, math.log(w.shape[0],10), base=10, num=10) if int(round(x)) not in logspace]\n",
    "p1=scoseno_k_diferencias(w1, logspace, sort_by=\"t0\")\n",
    "p2=scoseno_k_diferencias(w2, logspace, sort_by=\"t0\")\n",
    "p = pd.DataFrame()\n",
    "p[\"pomodoro\"] = p1[\"scos_r0_r1\"]\n",
    "p[\"lucciola\"] = p2[\"scos_r0_r1\"]\n",
    "p\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w1 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\").sort_values(by=\"t1\")\\nw2 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"lucciola\").sort_values(by=\"t1\")\\nlogspace = []\\n[logspace.append(int(round(x))) for x in np.logspace(5, math.log(w.shape[0],10), base=10, num=20) if int(round(x)) not in logspace]\\np1=wilcoxon_k_diferencias(w1, logspace, sort_by=\"dif_abs\")\\np2=wilcoxon_k_diferencias(w2, logspace, sort_by=\"dif_abs\")\\np = pd.DataFrame()\\np[\"pomodoro\"] = p1[\"wilcox_r0_r1\"]\\np[\"lucciola\"] = p2[\"wilcox_r0_r1\"]\\np'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wilcoxon_k_diferencias(nn2df,k_lista, sort_by=\"t0\"):\n",
    "    wilcoxondf = pd.DataFrame()\n",
    "    for k in k_lista:\n",
    "        if k >= 10:\n",
    "            dfk = nn2df.sort_values(by=sort_by, ascending=False)[[\"t0\",\"t1\",\"rank_0\",\"rank_1\"]].head(k)\n",
    "            alpha = 0.05\n",
    "            wilcox, p = wilcoxon(dfk[\"t0\"],dfk[\"t1\"])\n",
    "            wilcox_rank, p_rank = wilcoxon(dfk[\"rank_0\"],dfk[\"rank_1\"])\n",
    "            if p > alpha:\n",
    "                '''Same distribution (fail to reject H0)'''\n",
    "                w = 0   \n",
    "            else:\n",
    "                '''Different distribution (reject H0)'''\n",
    "                w = 1\n",
    "            if p_rank > alpha:\n",
    "                '''Same distribution (fail to reject H0)'''\n",
    "                w_rank = 0   \n",
    "            else:\n",
    "                '''Different distribution (reject H0)'''\n",
    "                w_rank = 1\n",
    "            w_series = pd.Series({\"wilcox_t0_t1\":w, \"wilcox_r0_r1\":w_rank})\n",
    "            w_series.name = k\n",
    "            wilcoxondf = wilcoxondf.append(w_series)\n",
    "    wilcoxondf.index.name = nn2df.index.name\n",
    "    return wilcoxondf\n",
    "        \n",
    "                          \n",
    "\"\"\"w1 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\").sort_values(by=\"t1\")\n",
    "w2 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"lucciola\").sort_values(by=\"t1\")\n",
    "logspace = []\n",
    "[logspace.append(int(round(x))) for x in np.logspace(5, math.log(w.shape[0],10), base=10, num=20) if int(round(x)) not in logspace]\n",
    "p1=wilcoxon_k_diferencias(w1, logspace, sort_by=\"dif_abs\")\n",
    "p2=wilcoxon_k_diferencias(w2, logspace, sort_by=\"dif_abs\")\n",
    "p = pd.DataFrame()\n",
    "p[\"pomodoro\"] = p1[\"wilcox_r0_r1\"]\n",
    "p[\"lucciola\"] = p2[\"wilcox_r0_r1\"]\n",
    "p\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparar entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\")\\nlogspace = []\\n[logspace.append(int(round(x))) for x in np.logspace(0.1, math.log(w.shape[0],10), base=10, num=5) if int(round(x)) not in logspace]\\ncomparacion_cbow_raw=comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, [\"pomodoro\",\"lucciolla\"], [\"scos\",\"scos_t0_t1\"], \"t0\",logspace)\\ncomparacion_cbow_raw = comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, get_wordlist(target_t0_dict, \"raw\"), [\"scos\",\"scos_t0_t1\"], \"t0\",logspace)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comparar_palabras(model1, model2, wordlist, compare, sort_by, k_lista):\n",
    "    print(\"comparando\")\n",
    "    comparacion = pd.DataFrame()\n",
    "    if type(wordlist[0]) == dict:\n",
    "        for enum, word in enumerate(wordlist):\n",
    "            print(f\"Palabra: {list(word.keys())[0]}, {enum} de {len(wordlist)}\", end=\"\\t\\t\\t\\t\\t\\t\\r\",flush=True)\n",
    "            nn = nn2df(model1, model2, list(word.keys())[0])\n",
    "            if compare[0] == \"promedio\":\n",
    "                c = promedio_k_diferencias(nn, k_lista, sort_by=\"t0\")[compare[1]]\n",
    "            if compare[0] == \"scos\":\n",
    "                c =scoseno_k_diferencias(nn,k_lista, sort_by=\"t0\")[compare[1]]\n",
    "            if compare[0] == \"wilcox\":\n",
    "                c = wilcoxon_k_diferencias(nn,k_lista, sort_by=\"t0\")[compare[1]]\n",
    "            c[\"golden\"] = word[list(word.keys())[0]]\n",
    "            c.name = nn.index.name\n",
    "            c.transpose()\n",
    "            comparacion = comparacion.append(c)\n",
    "            \n",
    "            \n",
    "    if type(wordlist[0]) == str:\n",
    "        for word in wordlist:\n",
    "            print(word, end=\"\\t\\t\\r\",flush=True)\n",
    "            nn = nn2df(model1, model2, word)\n",
    "            if compare[0] == \"promedio\":\n",
    "                c = promedio_k_diferencias(nn, k_lista, sort_by=\"t0\")[compare[1]]\n",
    "            if compare[0] == \"scos\":\n",
    "                c = scoseno_k_diferencias(nn,k_lista, sort_by=\"t0\")[compare[1]]\n",
    "            if compare[0] == \"wilcox\":\n",
    "                c = wilcoxon_k_diferencias(nn,k_lista, sort_by=\"t0\")[compare[1]]\n",
    "            c.transpose()\n",
    "            comparacion = comparacion.append(c)\n",
    "    \n",
    "    return comparacion\n",
    "            \n",
    "\"\"\"w = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"pomodoro\")\n",
    "logspace = []\n",
    "[logspace.append(int(round(x))) for x in np.logspace(0.1, math.log(w.shape[0],10), base=10, num=5) if int(round(x)) not in logspace]\n",
    "comparacion_cbow_raw=comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, [\"pomodoro\",\"lucciolla\"], [\"scos\",\"scos_t0_t1\"], \"t0\",logspace)\n",
    "comparacion_cbow_raw = comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, get_wordlist(target_t0_dict, \"raw\"), [\"scos\",\"scos_t0_t1\"], \"t0\",logspace)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparar entre grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximos_minimos(listo, words=False):\n",
    "    max_min = pd.DataFrame()\n",
    "    cambiaron = listo[listo[\"golden\"]==1].drop(\"golden\",axis=1)\n",
    "    nocambiaron = listo[listo[\"golden\"]==0].drop(\"golden\",axis=1)\n",
    "    print(cambiaron.shape, nocambiaron.shape)\n",
    "    \n",
    "    max_nocambio = nocambiaron.describe().loc[\"max\"]\n",
    "    max_nocambio.name = \"max_nocambio\"\n",
    "    min_nocambio = nocambiaron.describe().loc[\"min\"]\n",
    "    min_nocambio.name = \"min_nocambio\"\n",
    "    max_cambio = cambiaron.describe().loc[\"max\"]\n",
    "    max_cambio.name = \"max_cambio\"\n",
    "    min_cambio = cambiaron.describe().loc[\"min\"]\n",
    "    min_cambio.name = \"min_cambio\"\n",
    "\n",
    "    area_cambio = nocambiaron.describe().loc[\"max\"] - nocambiaron.describe().loc[\"min\"]\n",
    "    area_cambio.name = \"area_cambio\"\n",
    "    area_nocambio =  cambiaron.describe().loc[\"max\"] - cambiaron.describe().loc[\"min\"]\n",
    "    area_nocambio.name = \"area_nocambio\"\n",
    "    area_interseccion = nocambiaron.describe().loc[\"max\"] - cambiaron.describe().loc[\"min\"]\n",
    "    area_interseccion.name = \"area_interseccion\"\n",
    "    porcentage_inteseccion_cambio = area_interseccion/area_cambio\n",
    "    porcentage_inteseccion_cambio.name = \"por_inteseccion_cambio\"\n",
    "    porcentage_inteseccion_nocambio = area_interseccion/area_nocambio\n",
    "    porcentage_inteseccion_nocambio.name = \"por_inteseccion_nocambio\"\n",
    "    suma_porcentajes = porcentage_inteseccion_cambio+porcentage_inteseccion_nocambio\n",
    "    suma_porcentajes.name = \"suma_porcentajes\"\n",
    "    \n",
    "    max_min = max_min.append(max_nocambio)\n",
    "    max_min = max_min.append(min_nocambio)\n",
    "    max_min = max_min.append(max_cambio)\n",
    "    max_min = max_min.append(min_cambio)\n",
    "    max_min = max_min.append(area_cambio)\n",
    "    max_min = max_min.append(area_nocambio)\n",
    "    max_min = max_min.append(area_interseccion)\n",
    "    max_min = max_min.append(porcentage_inteseccion_cambio)\n",
    "    max_min = max_min.append(porcentage_inteseccion_nocambio)\n",
    "    max_min = max_min.append(suma_porcentajes)\n",
    "    \n",
    "    max_min = max_min.transpose()\n",
    "    \n",
    "    falsos_negativos = pd.DataFrame()\n",
    "    for (columnName, columnData) in cambiaron.transpose().iteritems():\n",
    "        falsos_serie = columnData < max_min[\"max_nocambio\"]\n",
    "        falsos_serie.name = columnName\n",
    "        falsos_negativos = falsos_negativos.append(falsos_serie)\n",
    "    max_min[\"FN\"] = falsos_negativos.sum()\n",
    "    \n",
    "    falsos_positivos = pd.DataFrame()\n",
    "    for (columnName, columnData) in nocambiaron.transpose().iteritems():\n",
    "        falsos_serie = columnData > max_min[\"min_cambio\"]\n",
    "        falsos_serie.name = columnName\n",
    "        falsos_positivos = falsos_positivos.append(falsos_serie)\n",
    "    max_min[\"FP\"] = falsos_positivos.sum()\n",
    "    \n",
    "    max_min[\"TP\"] = cambiaron.shape[0] - max_min[\"FN\"]\n",
    "    max_min[\"TN\"] = nocambiaron.shape[0] - max_min[\"FP\"]\n",
    "    \n",
    "    max_min[\"acurracy\"] = ( max_min[\"TP\"] + max_min[\"TN\"])/(cambiaron.shape[0]+nocambiaron.shape[0])\n",
    "    max_min[\"precision\"] = max_min[\"TP\"]/(max_min[\"TP\"]+max_min[\"FP\"])\n",
    "    max_min[\"recall\"] = max_min[\"TP\"]/(max_min[\"TP\"]+max_min[\"FN\"])\n",
    "    \n",
    "    if words:\n",
    "        for word in words:\n",
    "            x = listo.drop(\"golden\",axis=1).loc[word]\n",
    "            max_min[word] = x\n",
    "    \n",
    "    return max_min\n",
    "\n",
    "#mm = maximos_minimos(comparacion_cbow_raw_abst0)\n",
    "#mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparacion_cbow_raw_abst0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujar_por_goldstandard(df, porcentage=False):\n",
    "    \n",
    "    x = np.array(df.index,dtype=int)\n",
    "    if porcentage == True :\n",
    "        x = x/x.max()*100\n",
    "    \n",
    "    \n",
    "    plt.close(\"all\")\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 1, figure=fig)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ax1.plot(x, df[[\"max_nocambio\",\"min_nocambio\"]], color='blue', alpha=0.5)\n",
    "    ax1.plot(x, df[[\"max_cambio\",\"min_cambio\"]], color='orange', alpha=0.5)\n",
    "    ax1.plot(x, np.full(len(x), 0.25), '--', color='black', alpha=1, label=\"Threshold = 0.25\")\n",
    "    \n",
    "    #print(\"valores_quemados\")\n",
    "    #ax1.plot(x, df[\"polisportiva\"], \".\", color='blue', label=\"Polisportiva (Recurrent FP)\")\n",
    "    #ax1.plot(x, df[\"egemonizzare\"], \".\", color='red', label=\"Egemonizare (Recurrent FP)\")\n",
    "    \n",
    "    ax1.fill_between(x, df[\"max_cambio\"], df[\"min_cambio\"], where=(df[\"max_cambio\"] > df[\"min_cambio\"]), color='orange', alpha=0.2, label='Range between max and min\\n values for \"changing words\"')\n",
    "    ax1.fill_between(x, df[\"max_nocambio\"], df[\"min_nocambio\"], where=(df[\"max_nocambio\"] > df[\"min_nocambio\"]), color='blue', alpha=0.2,  label='Range between max and min\\n values for \"non changing words\"')\n",
    "    ax1.fill_between(x, df[\"max_nocambio\"], df[\"min_cambio\"], where=(df[\"max_nocambio\"] >  df[\"min_cambio\"]), color='yellow', alpha=1,  label='Intersection: Indecision range')\n",
    "    ax1.set_ylabel('cos_sim of $k$ nn in T0')\n",
    "    #ax1.axvline(x=10, ymin=0, ymax=1, linestyle=\"--\", label=\"k=10 (Our initial selection)\")\n",
    "    \n",
    "   \n",
    "    ax1.set_xscale(\"log\", basex=10)\n",
    "    #ax1.set_yscale(\"log\", basey=10)\n",
    "    legend_1 = ax1.legend(loc='bottom left', shadow=True, fontsize='x-small')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2.plot(x, df[\"acurracy\"] , color='red', label='Accuracy')\n",
    "    ax2.plot(x, df[\"precision\"] , color='blue',  label='Precision')\n",
    "    ax2.plot(x, df[\"recall\"] , color='black', label='Recall')\n",
    "    ax2.set_xscale(\"log\", basex=10)\n",
    "    ax2.set_xlabel('Top k nearest neighbors from the common vocabulary')\n",
    "    ax2.set_ylabel('Performance\\n with cos_dis=0.25')\n",
    "    legend_2 = ax2.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w1 = nn2df(mt0_raw_cbow, mt1_raw_cbow, \"lucciola\").sort_values(by=\"t1\")\n",
    "logspace = []\n",
    "[logspace.append(int(round(x))) for x in np.logspace(0.1, math.log(w1.shape[0],10), base=10, num=100) if int(round(x)) not in logspace]\n",
    "if \"pomodoro\" in list(target_t0_dict.keys()):\n",
    "    del target_t0_dict[\"pomodoro\"]\n",
    "#comparacion_cbow_raw_abst0 = comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, get_wordlist(target_t0_dict, \"raw\"), [\"promedio\",\"dif_abs\"], \"t0\",logspace)\n",
    "#comparacion_cbow_raw_abst1 = comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, get_wordlist(target_t0_dict, \"raw\"), [\"promedio\",\"dif_rank\"], \"t0\",logspace)\n",
    "comparacion_cbow_raw_cost0 = comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, get_wordlist(target_t0_dict, \"raw\"), [\"scos\",\"scos_t0_t1\"], \"t0\",logspace)\n",
    "#comparacion_cbow_raw_cosr1 = comparar_palabras(mt0_raw_cbow, mt1_raw_cbow, get_wordlist(target_t0_dict, \"raw\"), [\"scos\",\"scos_r0_r1\"], \"t0\",logspace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 91) (12, 91)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38192f1fdeb4fd3b89ba7fc2cc6e017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/001/usuarios/amnet04/anaconda3/envs/fullnlpai_fasttextbypip/lib/python3.7/site-packages/ipykernel_launcher.py:32: MatplotlibDeprecationWarning: Unrecognized location 'bottom left'. Falling back on 'best'; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "This will raise an exception in 3.3.\n"
     ]
    }
   ],
   "source": [
    "mm = maximos_minimos(comparacion_cbow_raw_cost0, [\"polisportiva\", \"egemonizzare\"])\n",
    "dibujar_por_goldstandard(mm)\n",
    "#comparacion_cbow_raw_abst0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 141,\n",
       " 'golden': 0,\n",
       " 'pos': {'propn': {'count': 63,\n",
       "   'lemmas': {'polisportire': {'count': 1},\n",
       "    'polisportiva': {'count': 61},\n",
       "    'polisportivo': {'count': 1}}},\n",
       "  'noun': {'count': 66,\n",
       "   'lemmas': {'polisportiva': {'count': 65}, 'polisportivo': {'count': 1}}},\n",
       "  'adj': {'count': 10,\n",
       "   'lemmas': {'polisportivo': {'count': 5},\n",
       "    'polisportiva': {'count': 4},\n",
       "    'polisportire': {'count': 1}}},\n",
       "  'verb': {'count': 2, 'lemmas': {'polisportiva': {'count': 2}}}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_t1_dict[\"polisportiva\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujar_4(df1, porcentage=False):\n",
    "    \n",
    "    x = np.array(df.index,dtype=int)\n",
    "    if porcentage == True :\n",
    "        x = x/x.max()*100\n",
    "    \n",
    "    \n",
    "    plt.close(\"all\")\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    gs = gridspec.GridSpec(1, 1, figure=fig)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ax1.plot(x, df[[\"max_nocambio\",\"min_nocambio\"]], color='blue', alpha=0.5)\n",
    "    ax1.plot(x, df[[\"max_cambio\",\"min_cambio\"]], color='orange', alpha=0.5)\n",
    "    ax1.plot(x, np.full(len(x), 0.16), '--', color='black', alpha=1, label=\"Suggested threshold = 0.16\")\n",
    "    \n",
    "    print(\"valores_quemados\")\n",
    "    ax1.plot(x, df[\"polisportiva\"], \".\", color='blue', label=\"Polisportiva (Recurrent FP)\")\n",
    "    ax1.plot(x, df[\"egemonizzare\"], \".\", color='red', label=\"Egemonizare (Recurrent FP)\")\n",
    "    \n",
    "    ax1.fill_between(x, df[\"max_cambio\"], df[\"min_cambio\"], where=(df[\"max_cambio\"] > df[\"min_cambio\"]), color='orange', alpha=0.2, label='Range between max and min\\n values for \"changing words\"')\n",
    "    ax1.fill_between(x, df[\"max_nocambio\"], df[\"min_nocambio\"], where=(df[\"max_nocambio\"] > df[\"min_nocambio\"]), color='blue', alpha=0.2,  label='Range between max and min\\n values for \"non changing words\"')\n",
    "    ax1.fill_between(x, df[\"max_nocambio\"], df[\"min_cambio\"], where=(df[\"max_nocambio\"] >  df[\"min_cambio\"]), color='yellow', alpha=1,  label='Intersection: Indecision range')\n",
    "    ax1.set_ylabel('avg.abs.diff\\n of the target words')\n",
    "    ax1.axvline(x=10, ymin=0, ymax=1, linestyle=\"--\", label=\"k=10 (Our initial selection)\")\n",
    "    \n",
    "   \n",
    "    ax1.set_xscale(\"log\", basex=10)\n",
    "    #ax1.set_yscale(\"log\", basey=10)\n",
    "    legend_1 = ax1.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparacion_cbow_raw_abst0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-022afb532440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaximos_minimos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparacion_cbow_raw_abst0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"polisportiva\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"egemonizzare\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdibujar_raritas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comparacion_cbow_raw_abst0' is not defined"
     ]
    }
   ],
   "source": [
    "mm = maximos_minimos(comparacion_cbow_raw_abst0, [\"polisportiva\", \"egemonizzare\"])\n",
    "dibujar_raritas(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion_cbow_raw_cost0.columns\n",
    "comparacion_cbow_raw_cost0[[3,2]].sort_values(by=3)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion_cbow_raw_cost0[[3,2]].sort_values(by=2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([comparacion_cbow_raw_cost0[[3,2]].sort_values(by=3)[:5],comparacion_cbow_raw_cost0[[3,2]].sort_values(by=2)[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparar_con_ham(df1, df2, porcentage=False):\n",
    "    \n",
    "    x = np.array(df1.index,dtype=int)\n",
    "    if porcentage == True :\n",
    "        x = x/x.max()*100\n",
    "    \n",
    "    plt.close(\"all\")\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ax1.plot(x, df1[[\"max_nocambio\",\"min_nocambio\"]], color='blue', alpha=0.5)\n",
    "    ax1.plot(x, df1[[\"max_cambio\",\"min_cambio\"]], color='orange', alpha=0.5)\n",
    "    ax1.plot(x, np.full(len(x), 0.25), '--', color='black', alpha=1, label=\"Suggested threshold = 0.25\")\n",
    "    \n",
    "    #print(\"valores_quemados\")\n",
    "    #ax1.plot(x, df[\"polisportiva\"], \".\", color='blue', label=\"Polisportiva (Recurrent FP)\")\n",
    "    #ax1.plot(x, df[\"egemonizzare\"], \".\", color='red', label=\"Egemonizare (Recurrent FP)\")\n",
    "    \n",
    "    ax1.fill_between(x, df1[\"max_cambio\"], df1[\"min_cambio\"], where=(df1[\"max_cambio\"] > df1[\"min_cambio\"]), color='orange', alpha=0.2, label='Range between max and min\\n values for \"changing words\"')\n",
    "    ax1.fill_between(x, df1[\"max_nocambio\"], df1[\"min_nocambio\"], where=(df1[\"max_nocambio\"] > df1[\"min_nocambio\"]), color='blue', alpha=0.2,  label='Range between max and min\\n values for \"non changing words\"')\n",
    "    ax1.fill_between(x, df1[\"max_nocambio\"], df1[\"min_cambio\"], where=(df1[\"max_nocambio\"] >  df1[\"min_cambio\"]), color='yellow', alpha=1,  label='Intersection: Indecision range')\n",
    "    ax1.set_ylabel('cos_dis of the\\n union of $k$ nn in T0 and T1')\n",
    "    #ax1.axvline(x=10, ymin=0, ymax=1, linestyle=\"--\", label=\"k=10 (Our initial selection)\")\n",
    "    \n",
    "   \n",
    "    ax1.set_xscale(\"log\", basex=10)\n",
    "    #ax1.set_yscale(\"log\", basey=10)\n",
    "    legend_1 = ax1.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2.plot(x, df1[\"acurracy\"] , color='red', label='Accuracy')\n",
    "    ax2.plot(x, df1[\"precision\"] , color='blue',  label='Precision')\n",
    "    ax2.plot(x, df1[\"recall\"] , color='black', label='Recall')\n",
    "    ax2.set_xscale(\"log\", basex=10)\n",
    "    ax2.set_xlabel('Top k nearest neighbors from the common vocabulary')\n",
    "    ax2.set_ylabel('Performance\\n with cos_dis=0.25')\n",
    "    legend_2 = ax2.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 1])\n",
    "    ax3.plot(x, df2[[\"max_nocambio\",\"min_nocambio\"]], color='blue', alpha=0.5)\n",
    "    ax3.plot(x, df2[[\"max_cambio\",\"min_cambio\"]], color='orange', alpha=0.5)\n",
    "    ax3.plot(x, np.full(len(x), 0.25), '--', color='black', alpha=1, label=\"Suggested threshold = 0.25\")\n",
    "    \n",
    "    #print(\"valores_quemados\")\n",
    "    #ax1.plot(x, df[\"polisportiva\"], \".\", color='blue', label=\"Polisportiva (Recurrent FP)\")\n",
    "    #ax1.plot(x, df[\"egemonizzare\"], \".\", color='red', label=\"Egemonizare (Recurrent FP)\")\n",
    "    \n",
    "    ax3.fill_between(x, df2[\"max_cambio\"], df2[\"min_cambio\"], where=(df2[\"max_cambio\"] > df2[\"min_cambio\"]), color='orange', alpha=0.2, label='Range between max and min\\n values for \"changing words\"')\n",
    "    ax3.fill_between(x, df2[\"max_nocambio\"], df2[\"min_nocambio\"], where=(df2[\"max_nocambio\"] > df2[\"min_nocambio\"]), color='blue', alpha=0.2,  label='Range between max and min\\n values for \"non changing words\"')\n",
    "    ax3.fill_between(x, df2[\"max_nocambio\"], df2[\"min_cambio\"], where=(df2[\"max_nocambio\"] >  df2[\"min_cambio\"]), color='yellow', alpha=1,  label='Intersection: Indecision range')\n",
    "    ax3.set_ylabel('cos_dis of the\\n union of $k$ nn in T0 and T1')\n",
    "    #ax1.axvline(x=10, ymin=0, ymax=1, linestyle=\"--\", label=\"k=10 (Our initial selection)\")\n",
    "    \n",
    "   \n",
    "    ax3.set_xscale(\"log\", basex=10)\n",
    "    #ax1.set_yscale(\"log\", basey=10)\n",
    "    legend_3 = ax3.legend(loc='upper right', shadow=True, fontsize='x-small')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax4.plot(x, df2[\"acurracy\"] , color='red', label='Accuracy')\n",
    "    ax4.plot(x, df2[\"precision\"] , color='blue',  label='Precision')\n",
    "    ax4.plot(x, df2[\"recall\"] , color='black', label='Recall')\n",
    "    ax4.set_xscale(\"log\", basex=10)\n",
    "    ax4.set_xlabel('Top k nearest neighbors from the common vocabulary')\n",
    "    ax4.set_ylabel('Performance\\n with cos_dis=0.25')\n",
    "    legend_4 = ax4.legend(loc='upper right', shadow=True, fontsize='x-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 91) (12, 91)\n",
      "(6, 91) (12, 91)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e708bd5d89a345898a290a9ac26ce22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/001/usuarios/amnet04/anaconda3/envs/fullnlpai_fasttextbypip/lib/python3.7/site-packages/ipykernel_launcher.py:62: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    }
   ],
   "source": [
    "mm1 = maximos_minimos(comparacion_cbow_raw_abst0, [\"polisportiva\", \"egemonizzare\"])\n",
    "mm2 = maximos_minimos(comparacion_cbow_raw_cost0, [\"polisportiva\", \"egemonizzare\"])\n",
    "comparar_con_ham(mm1,mm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vocab = [x for if target_word in list(model0.wv.vocab) and target_word in list(model1.wv.vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-ea200d2a58b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmt0_raw_cbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "list[mt0_raw_cbow.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fullnlpai_fasttextbypip] *",
   "language": "python",
   "name": "conda-env-fullnlpai_fasttextbypip-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
